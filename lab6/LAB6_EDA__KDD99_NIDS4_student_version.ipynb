{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://esprit.tn\"><img src = \"https://upload.wikimedia.org/wikipedia/commons/f/ff/Logo_ESPRIT_Ariana.jpg\" width = 300, align = \"center\"></a>\n",
    "\n",
    "\n",
    "\n",
    "<h1 align=center><font size = 5>Lab 6: KDD-99 - EDA - Data understanding / Data pre-processing -  hands-on  </font></h1>\n",
    "\n",
    "Estimated duration: 150 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "The Current lab aims to introduce python capabilities in managing data \n",
    "<li>Loading data </li>\n",
    "<li> data understanding </li>\n",
    "<li>Data preparation with Pandas</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Data Understanding  </font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h3 align=center>I. Loading data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 align=center>I.1 Reading data raw format</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './kddcup.data_10_percent_corrected'\n",
    "path_meta= './kddcup.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000040\n",
      "Elapsed time 0:00:00.000028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "t=datetime.datetime.now()\n",
    "print(datetime.datetime.now()- t)\n",
    "\n",
    "def init_chrono():\n",
    "    return datetime.datetime.now()\n",
    "\n",
    "def elapsed_time(t):\n",
    "    if t:\n",
    "        delta = init_chrono() - t\n",
    "        print ('Elapsed time', delta)\n",
    "        return delta \n",
    "    \n",
    "# test\n",
    "t = init_chrono()\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494021\n",
      "Elapsed time 0:00:00.988984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=988984)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= init_chrono()\n",
    "with open(path,\"r\") as file1:\n",
    "    FileContent=file1.readlines()\n",
    "    print(len(FileContent))\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first line of the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.\n",
      "\n",
      "0,tcp,http,SF,219,1234,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,35,0.00,0.00,0.00,0.00,1.00,0.00,0.14,6,255,1.00,0.00,0.17,0.05,0.00,0.01,0.00,0.00,normal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(FileContent[0])\n",
    "print(FileContent[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration: continuous.\\n', 'protocol_type: symbolic.\\n', 'service: symbolic.\\n', 'flag: symbolic.\\n', 'src_bytes: continuous.\\n', 'dst_bytes: continuous.\\n', 'land: symbolic.\\n', 'wrong_fragment: continuous.\\n', 'urgent: continuous.\\n', 'hot: continuous.\\n', 'num_failed_logins: continuous.\\n', 'logged_in: symbolic.\\n', 'num_compromised: continuous.\\n', 'root_shell: continuous.\\n', 'su_attempted: continuous.\\n', 'num_root: continuous.\\n', 'num_file_creations: continuous.\\n', 'num_shells: continuous.\\n', 'num_access_files: continuous.\\n', 'num_outbound_cmds: continuous.\\n', 'is_host_login: symbolic.\\n', 'is_guest_login: symbolic.\\n', 'count: continuous.\\n', 'srv_count: continuous.\\n', 'serror_rate: continuous.\\n', 'srv_serror_rate: continuous.\\n', 'rerror_rate: continuous.\\n', 'srv_rerror_rate: continuous.\\n', 'same_srv_rate: continuous.\\n', 'diff_srv_rate: continuous.\\n', 'srv_diff_host_rate: continuous.\\n', 'dst_host_count: continuous.\\n', 'dst_host_srv_count: continuous.\\n', 'dst_host_same_srv_rate: continuous.\\n', 'dst_host_diff_srv_rate: continuous.\\n', 'dst_host_same_src_port_rate: continuous.\\n', 'dst_host_srv_diff_host_rate: continuous.\\n', 'dst_host_serror_rate: continuous.\\n', 'dst_host_srv_serror_rate: continuous.\\n', 'dst_host_rerror_rate: continuous.\\n', 'dst_host_srv_rerror_rate: continuous.\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(path_meta,\"r\") as file1:\n",
    "    FileContent_meta=file1.readlines()\n",
    "    print((FileContent_meta[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h4 align=center>I.2 Reading data csv and Pandas </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 0:00:03.084422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=3, microseconds=84422)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= init_chrono()\n",
    "lines=[]\n",
    "with open(path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for l in reader:\n",
    "        lines.append(l)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Loaded data :  (494021, 42)\n",
      "dataset's type: <class 'pandas.core.frame.DataFrame'>\n",
      "Elapsed time 0:00:02.433312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=2, microseconds=433312)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= init_chrono()\n",
    "dataset=  pnd.read_csv(path, header=None)\n",
    "print(type(dataset.index.values))\n",
    "print('Loaded data : ', dataset.shape)\n",
    "print(\"dataset's type: {}\".format(type(dataset)))\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of useful information returned by the shape attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-b2d8c0f9f071>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-b2d8c0f9f071>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    The number of entries\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The number of entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible to print the whole dataset?\n",
    "Suggest an alternative solution ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can but it will be slow and unformatted. Print a limited number with the good formating options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following block code you may find the answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the data set has a true header? What was assumed as a header?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No. Data columns names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the data set has a true header? What was considered as a header?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No. The first line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=center>I.3 Handling headers </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the following attributes can be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To create headers and manipulate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.columns)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the data set with  ***header*** parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= init_chrono()\n",
    "dataset=  pnd.read_csv(path, header=None)\n",
    "print ('Loaded data : ', dataset.shape)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What changed ? What about header ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The first line is considered as data. The head becomes mere indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So can you guess how to change headers with column names ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load the header file and change the object that point to the header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the file ***kddcup.names*** contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it containers the header of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_meta, \"r\") as header_file:\n",
    "    header_lines = header_file.readlines()\n",
    "print(header_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How to geberate a list for column names as follow:***\n",
    "    \n",
    "    \n",
    "   lst = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_dict = dict(map(lambda x: x[:-2].replace(' ', '').split(':'), header_lines[1:]))\n",
    "print(header_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the transformation process in a couple of steps:\n",
    "    <ol>\n",
    "    <li>Step 1: </li>\n",
    "    <li>Step 2: </li>\n",
    "    <li>Step 3: </li>\n",
    "    <li>...</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We would want to to extract the key, value couple and remove the '\\n' char from the value, then just add the analyst\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features ={}\n",
    "attributes = header_lines[1:]\n",
    "for a in attributes:\n",
    "    k,v = a.split(':')\n",
    "    features[k]= v[:len(v)-2]\n",
    "    \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(header_dict.keys())\n",
    "columns.append('class')\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why we append class to the list? \n",
    "Where will be inserted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Because we need an analyst decision, to identify normal traffic from attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It will be inserted last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we assign column names (***header***) to the dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By simple affectation x = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=center>I.4 Saving the new dataset  </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **dataset.to_csv()** method to save the new version of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    out= dataset.to_csv('./new_dataset.csv')\n",
    "    print(out)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the above version more secure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes, because it handles exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the recently saved data by cheking the first lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines(csvf, n):\n",
    "    lines=[]\n",
    "    with open(csvf, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for l in reader:\n",
    "            lines.append(l)\n",
    "            if len(lines) == n:\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def lines_head(csvf, n):\n",
    "    print(pnd.read_csv(csvf).head(n))\n",
    "\n",
    "for i in lines('./new_dataset.csv', 1):\n",
    "    print(i)\n",
    "\n",
    "lines_head('./new_dataset.csv', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=center>II. Data understanding </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>II.1 Accessing DataFrame content </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question :*** list colum names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select column **duration** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= dataset[['duration', 'service']]\n",
    "d1 = dataset.loc[dataset.index[:4], ['protocol_type', 'class']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(d))\n",
    "print(type(d1))\n",
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check the dimensions of d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check the dimensions of d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between the two methods ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one selects a sub dataframe the other selects a series (value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a subset with a reduced set of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset[['duration', 'protocol_type', 'service', 'flag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check **dataset2** dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice :***\n",
    "    - build a dataset (DataFrame) with the following attributes: 'duration', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'wrong_fragment' and class\n",
    "    - save the resulting data set in a csv format\n",
    "    - load the new data set and print file header and the last 5 rows.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = dataset[['duration', 'service', 'flag', 'src_bytes', 'wrong_fragment', 'class']]\n",
    "def save_ds_to_csv(target, source_ds):\n",
    "    try:\n",
    "        out= source_ds.to_csv(target, index=False)\n",
    "        print(out)\n",
    "        return target\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "tf = save_ds_to_csv('./ds3.csv', ds3)\n",
    "ds4 = pnd.read_csv(tf)\n",
    "ds4.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecing cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the result of the following  instructions:  a cell value cell(x, y) by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1= dataset.ix[0,0]\n",
    "print(val1)\n",
    "val2= dataset.ix[10000,41]\n",
    "print (\"val2\", val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the same block of code with: ***iloc***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1= dataset.iloc[0,0]\n",
    "print(val1)\n",
    "val2= dataset.iloc[0,41]\n",
    "print (\"val2\", val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between the 2 mathods ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nothing, only that ix is deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting data with column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val= dataset.ix[9990,'service']\n",
    "print(val)\n",
    "val2=dataset.loc[9990,'service']\n",
    "print(val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with ***iloc*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = dataset.iloc[0, 2]\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val3= dataset['service'][0]\n",
    "print(val3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.service[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many facilities to select values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a range of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = dataset.ix[0:4, 0:3]\n",
    "print(type(vals) )\n",
    "save_ds_to_csv('./vals_ds.csv', vals)\n",
    "vals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we save the result in a file ? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we can as they are DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the subset of data resulting from the following code ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset.loc[0:3, 'service':'class']\n",
    "print(type(dataset3))\n",
    "print(dataset3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it returns a sub dataset that have columns th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionnal data selection: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code and print the head od the resunting dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = dataset[dataset['duration']>0]\n",
    "print(dataset4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it prints data through filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice ***\n",
    "- select the rows with normal behavior and save theme to csv file \n",
    "- print the size of the resulting dataset (dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_normal = dataset[dataset['class'] == 'normal.']\n",
    "save_ds_to_csv('./normal.csv', dataset_normal)\n",
    "print(dataset_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>II.2 Basic stat summary : Basic data insights </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the new file in raw mode(without using pandas), and check the first lines ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the loaded dataset attribute types with **dtypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes\n",
    "raw_ds = csv.reader(open('./normal.csv', 'r'))\n",
    "for i in raw_ds:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are colunmns with names more intresting than colunms with numeric indexes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes they are, as they make the access more intuitive thus easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the ***describe()*** method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the type of returned summary table? Is it advantageous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame, yes as we can treat statistics themselves as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are all attributes present in the startistical summary ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How to add the remaining attributes? use *** describe()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the error source ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the type, some attributes have no numerical meaning (objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try the following parameter: ***include=['object']***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the output of the above method? What about the first column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the index, summary of the dtype and memory usage of every dtype (from dataset.info.__doc__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try the following code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= dataset['class'].unique()\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to select unique values by column\n",
    "gdf = dataset.groupby(['class', 'duration'])\n",
    "indexes = [gpk[0] for gpk in gdf.groups.values()]\n",
    "gdf  = dataset.reindex(indexes)\n",
    "gdf.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count the possible unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count the possible unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(ds, key):\n",
    "    return len(ds[key].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the method ****value_counts()**** for a given column. What kind of stats could be derived ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(value_counts(dataset, 'flag'))\n",
    "print(len(dataset.loc[:,'flag'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice:***\n",
    "\n",
    "    - Generate the unique values for the service attribute \n",
    "    - build and save a dataset including all columns for the more frequent found value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "#slow !!!\n",
    "def key_to_freq(ds, key):\n",
    "    frequency = collections.defaultdict(int)\n",
    "    for i in ds[key].unique():\n",
    "        for j in ds[key]:\n",
    "            frequency[i] += 1 if j == i else 0\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "def most_freq_to_ds(ds, limit_freq, key):\n",
    "    freq = key_to_freq(ds, key)\n",
    "    print(freq)\n",
    "    lst = list(filter(lambda x: freq[x] >= limit_freq, freq))\n",
    "    ret_ds = pnd.DataFrame()\n",
    "    for i in lst:\n",
    "        ret_ds = ret_ds.append(ds[ds[key] == i])\n",
    "      \n",
    "    \n",
    "    return ret_ds\n",
    "\n",
    "#most_freq_to_ds(dataset, 600, 'service')\n",
    "#group = dataset.groupby('service')\n",
    "#gps = [gp[0] for gp in group.groups.values()]\n",
    "#unique_ds = dataset.reindex(gps)\n",
    "#unique_ds['service'].head()\n",
    "\n",
    "unique_service = dataset.service.unique()\n",
    "most_freq_service = dataset[dataset['service'] == dataset.service.value_counts().index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=center>III Basic Data pre-processing data wrangling </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the purpose of Data Wrangling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling is the process of converting data from the initial format to a format that may be better for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "### 1. Identify and handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating for Missing Data\n",
    "\n",
    "The missing values are converted to Python's default. We use Python's built-in functions to identify these missing values. There are two methods to detect missing data:\n",
    "1.  **.isnull()**\n",
    "2.  **.notnull()**\n",
    "\n",
    "The output is a boolean value indicating whether the passed in argument value are in fact missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b395679b381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmissing_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmissing_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "missing_data = dataset[dataset.isnull() == True]\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull()[dataset.isnull()['src_bytes'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count missing values in each column\n",
    "Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value, \"False\"  means the value is present in the dataset.  In the body of the for loop the method  \".value_couts()\"  counts the number of \"True\" values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in missing_data.columns:\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Could you decode the sentenses of the previous code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It loops through the values of missing_data columns and counts how many are missing (the number of True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What conclusion could be derived from the above returned results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Our dataset is sane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref3\"></a>\n",
    "## Deal with missing data\n",
    "**How to deal with missing data?**\n",
    "\n",
    "    \n",
    "    1. drop data \n",
    "        a. drop the whole row\n",
    "        b. drop the whole column\n",
    "    2. replace data\n",
    "        a. replace it by mean\n",
    "        b. replace it by frequency\n",
    "        c. replace it based on other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing 'col_N' values by the most frequent \n",
    "most_freq= 'val'\n",
    "df[\"col_N\"].replace(np.nan,most_freq, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Why we use inplace=true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To replace in the same place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop all rows that do not have price data (we assume that df is dataframe having a price column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simply drop whole row with NaN in \"price\" column\n",
    "df.dropna(subset=[\"price\"], axis=0, inplace = True)\n",
    "\n",
    "# reset index, because we droped two rows\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "## 2 Correct  data format\n",
    "**We are almost there!**\n",
    "<div>The last step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).</div>\n",
    "\n",
    "In Pandas, we use \n",
    "<div>**.dtype()** to check the data type</div>\n",
    "<div>**.astype()** to change the data type</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets list the data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assume that the duration column was able to receive float value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duration=dataset.duration.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, move it back to the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duration = dataset.duration.astype('int')\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref5\"></a>\n",
    "### 3 Data Standardization\n",
    "Data is usually collected from different agencies with different formats.\n",
    "(Data Standardization is also a term for a particular type of data normalization, where we subtract the mean and divide by the standard deviation)\n",
    "\n",
    "**What is Standardization?**\n",
    "<div>Standardization is the process of transforming data into a common format which allows the researcher to make the meaningful comparison.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add column 'duration_m' which reprent the duration of the connection in minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['duration_m'] = dataset['duration'] // 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref6\"></a>\n",
    "### 4 Data Normalization \n",
    "\n",
    "**Why normalization?**\n",
    "<div>Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variable variance is 1, or scaling variable so the variable values range from 0 to 1\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using describe method identify the attributes that are already normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['class'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h4 align=center>I.2 dataset attributes </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark Site:\n",
    "    http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark description: \n",
    "    - http://kdd.ics.uci.edu/databases/kddcup99/task.html\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set description:\n",
    "    A connection is a sequence of TCP packets starting and ending at some well defined times,\n",
    "    between which data flows to and from a source IP address to a target IP address under some well defined protocol.\n",
    "    Each connection is labeled as either normal, or as an attack, with exactly one specific attack type.\n",
    "    Each connection record consists of about 100 bytes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attacks fall into four main categories: \n",
    "     <li> DOS: denial-of-service, e.g. syn flood;</il>\n",
    "     <li>R2L: unauthorized access from a remote machine, e.g. guessing password;</il>\n",
    "     <li>U2R:  unauthorized access to local superuser (root) privileges, e.g., various 'buffer overflow' attacks;</il>\n",
    "    <li> probing: surveillance and other probing, e.g., port scanning.</il>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features or attributes fall into three main categories: \n",
    "      <li>Basic features of individual TCP connections</il>\n",
    "     <li>Content features within a connection suggested by domain knowledge</il>\n",
    "     <li>Traffic features computed using a two-second time window</il>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The entire Lab should be sent to the NIDS Slack group before TUESDAY NOV 06th AT 8:00 am. The labs should be sent as direct messages and not published on the general or any public slack channel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <hr>\n",
    "Copyright &copy; Oct-2018 Dr.Amir Esseghir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
