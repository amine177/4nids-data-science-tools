{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://esprit.tn\"><img src = \"https://upload.wikimedia.org/wikipedia/commons/f/ff/Logo_ESPRIT_Ariana.jpg\" width = 300, align = \"center\"></a>\n",
    "\n",
    "\n",
    "\n",
    "<h1 align=center><font size = 5>Lab 9: Supervised learning -  Artificial Neural Networks (ANN) </font></h1>\n",
    "\n",
    "Estimated duration: 90 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEBOU DJEUFO Laurel Toussaint 4NIDS2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 9: IDS BASED ON MACHINE LEARNING TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim through this lab to build a robust intrusion detection system (IDS) based on a set of machine learning techinques.\n",
    "Various techniques will be explored and experimented to assess IDS robustness according to two criteria:\n",
    "    - maximizing the number of atatcks  detected \n",
    "    - reducing the number of false positive alerts\n",
    "The experiemtal study will cover the following methods:\n",
    "    - ANN\n",
    "    - Decision trees / random forest\n",
    "    - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Data loading and preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data preprare columns for ANN as done in the mini_lab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pnd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, zero_one_loss)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, classification_report,auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000073\n",
      "Elapsed time 0:00:00.000034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "t=datetime.datetime.now()\n",
    "print(datetime.datetime.now()- t)\n",
    "\n",
    "def init_chrono():\n",
    "    return datetime.datetime.now()\n",
    "\n",
    "def elapsed_time(t):\n",
    "    if t:\n",
    "        delta = init_chrono() - t\n",
    "        print ('Elapsed time', delta)\n",
    "        return delta \n",
    "    \n",
    "# test\n",
    "t = init_chrono()\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data (494021, 42) \n",
      " test_data: (311029, 42)\n"
     ]
    }
   ],
   "source": [
    "data_path = './'\n",
    "traindata = pnd.read_csv(data_path+'train.csv', header=None)\n",
    "testdata = pnd.read_csv(data_path+'test.csv', header=None)\n",
    "\n",
    "print('train_data', traindata.shape, '\\n', 'test_data:', testdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Build 3 neural networks with respecitvely 2 hidden layers, one hidden layer, and a learning rate equal to .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neural_network as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset before  distribution:\n",
      " smurf.              280790\n",
      "neptune.            107201\n",
      "normal.              97278\n",
      "back.                 2203\n",
      "satan.                1589\n",
      "ipsweep.              1247\n",
      "portsweep.            1040\n",
      "warezclient.          1020\n",
      "teardrop.              979\n",
      "pod.                   264\n",
      "nmap.                  231\n",
      "guess_passwd.           53\n",
      "buffer_overflow.        30\n",
      "land.                   21\n",
      "warezmaster.            20\n",
      "imap.                   12\n",
      "rootkit.                10\n",
      "loadmodule.              9\n",
      "ftp_write.               8\n",
      "multihop.                7\n",
      "phf.                     4\n",
      "perl.                    3\n",
      "spy.                     2\n",
      "Name: 41, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def show_dist(df_column, tag = 'Column'):\n",
    "    if not df_column.empty: \n",
    "        dist = df_column.value_counts()\n",
    "        print(\"%s distribution:\\n\" %tag, dist)\n",
    "\n",
    "#Test\n",
    "show_dist(traindata[41], tag=\"train dataset before \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical(dataframe):\n",
    "    types = dataframe.dtypes\n",
    "    i = 0\n",
    "    lst_cat=[]\n",
    "    for var in types:\n",
    "        if var == 'object':\n",
    "            print(i)\n",
    "            lst_cat.append(i)\n",
    "        i=i+1\n",
    "    return lst_cat\n",
    "\n",
    "def handle_categorical(dataframe):\n",
    "    if type(dataframe) != pnd.DataFrame:\n",
    "        return None \n",
    "\n",
    "    lst= get_categorical(dataframe)\n",
    "    \n",
    "    print('%d variables are categorical %s ' %(len(lst), lst))\n",
    "    for var_cat in lst:\n",
    "        try:\n",
    "            enc = sk.preprocessing.label.LabelEncoder()\n",
    "            show_dist(dataframe[var_cat], 'Var[' + str(var_cat) + '] (before)')\n",
    "            dataframe[var_cat] = enc.fit_transform(dataframe[var_cat])\n",
    "            show_dist(dataframe[var_cat], 'Var[' + str(var_cat) + '] (after)')\n",
    "        except Exception as e:\n",
    "            print('Exception: Unable to convert categorical variable ', var_cat, e)\n",
    "            \n",
    "    #return dataframe\n",
    "#handle_categorical(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata[41]=traindata[41].map(lambda x: 0 if x=='normal.' else 1)\n",
    "testdata[41]=testdata[41].map(lambda x: 0 if x=='normal.' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_dataset: distribution:\n",
      " 1    396743\n",
      "0     97278\n",
      "Name: 41, dtype: int64\n",
      "Test_dataset: distribution:\n",
      " 1    250436\n",
      "0     60593\n",
      "Name: 41, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "show_dist(traindata[41], 'Train_dataset:')\n",
    "show_dist(testdata[41], 'Test_dataset:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "3 variables are categorical [1, 2, 3] \n",
      "Var[1] (before) distribution:\n",
      " icmp    164969\n",
      "tcp     119357\n",
      "udp      26703\n",
      "Name: 1, dtype: int64\n",
      "Var[1] (after) distribution:\n",
      " 0    164969\n",
      "1    119357\n",
      "2     26703\n",
      "Name: 1, dtype: int64\n",
      "Var[2] (before) distribution:\n",
      " ecr_i          164352\n",
      "private         78510\n",
      "http            41237\n",
      "smtp             8268\n",
      "pop_3            3972\n",
      "domain_u         3160\n",
      "ftp_data         2223\n",
      "other            2185\n",
      "telnet           2077\n",
      "ftp               837\n",
      "eco_i             547\n",
      "imap4             333\n",
      "finger            291\n",
      "sunrpc            195\n",
      "auth              150\n",
      "time               82\n",
      "ntp_u              80\n",
      "echo               69\n",
      "domain             68\n",
      "link               66\n",
      "bgp                66\n",
      "netstat            65\n",
      "gopher             65\n",
      "remote_job         65\n",
      "netbios_ns         64\n",
      "ctf                63\n",
      "urp_i              63\n",
      "nntp               62\n",
      "uucp               62\n",
      "iso_tsap           62\n",
      "                ...  \n",
      "kshell             60\n",
      "name               60\n",
      "netbios_dgm        59\n",
      "nnsp               59\n",
      "ldap               59\n",
      "rje                58\n",
      "courier            58\n",
      "printer            58\n",
      "systat             57\n",
      "mtp                56\n",
      "ssh                56\n",
      "uucp_path          56\n",
      "Z39_50             55\n",
      "efs                55\n",
      "sql_net            54\n",
      "shell              53\n",
      "vmnet              53\n",
      "daytime            53\n",
      "netbios_ssn        53\n",
      "whois              52\n",
      "csnet_ns           50\n",
      "klogin             50\n",
      "supdup             50\n",
      "hostnames          48\n",
      "IRC                24\n",
      "pm_dump            16\n",
      "X11                15\n",
      "tim_i               7\n",
      "icmp                2\n",
      "tftp_u              1\n",
      "Name: 2, Length: 65, dtype: int64\n",
      "Var[2] (after) distribution:\n",
      " 14    164352\n",
      "46     78510\n",
      "22     41237\n",
      "50      8268\n",
      "44      3972\n",
      "11      3160\n",
      "19      2223\n",
      "41      2185\n",
      "56      2077\n",
      "18       837\n",
      "13       547\n",
      "25       333\n",
      "17       291\n",
      "53       195\n",
      "3        150\n",
      "59        82\n",
      "40        80\n",
      "12        69\n",
      "10        68\n",
      "4         66\n",
      "30        66\n",
      "20        65\n",
      "37        65\n",
      "47        65\n",
      "35        64\n",
      "60        63\n",
      "7         63\n",
      "26        62\n",
      "39        62\n",
      "61        62\n",
      "       ...  \n",
      "23        60\n",
      "9         60\n",
      "29        59\n",
      "34        59\n",
      "38        59\n",
      "5         58\n",
      "48        58\n",
      "45        58\n",
      "55        57\n",
      "52        56\n",
      "62        56\n",
      "32        56\n",
      "2         55\n",
      "15        55\n",
      "51        54\n",
      "8         53\n",
      "49        53\n",
      "63        53\n",
      "36        53\n",
      "64        52\n",
      "27        50\n",
      "6         50\n",
      "54        50\n",
      "21        48\n",
      "0         24\n",
      "42        16\n",
      "1         15\n",
      "58         7\n",
      "24         2\n",
      "57         1\n",
      "Name: 2, Length: 65, dtype: int64\n",
      "Var[3] (before) distribution:\n",
      " SF        248379\n",
      "REJ        41945\n",
      "S0         18012\n",
      "RSTO        1393\n",
      "RSTR         872\n",
      "S3           289\n",
      "SH            84\n",
      "S1            27\n",
      "S2            22\n",
      "OTH            4\n",
      "RSTOS0         2\n",
      "Name: 3, dtype: int64\n",
      "Var[3] (after) distribution:\n",
      " 9     248379\n",
      "1      41945\n",
      "5      18012\n",
      "2       1393\n",
      "4        872\n",
      "8        289\n",
      "10        84\n",
      "6         27\n",
      "7         22\n",
      "0          4\n",
      "3          2\n",
      "Name: 3, dtype: int64\n",
      "1\n",
      "2\n",
      "3\n",
      "3 variables are categorical [1, 2, 3] \n",
      "Var[1] (before) distribution:\n",
      " icmp    283602\n",
      "tcp     190065\n",
      "udp      20354\n",
      "Name: 1, dtype: int64\n",
      "Var[1] (after) distribution:\n",
      " 0    283602\n",
      "1    190065\n",
      "2     20354\n",
      "Name: 1, dtype: int64\n",
      "Var[2] (before) distribution:\n",
      " ecr_i          281400\n",
      "private        110893\n",
      "http            64293\n",
      "smtp             9723\n",
      "other            7237\n",
      "domain_u         5863\n",
      "ftp_data         4721\n",
      "eco_i            1642\n",
      "ftp               798\n",
      "finger            670\n",
      "urp_i             538\n",
      "telnet            513\n",
      "ntp_u             380\n",
      "auth              328\n",
      "pop_3             202\n",
      "time              157\n",
      "csnet_ns          126\n",
      "remote_job        120\n",
      "gopher            117\n",
      "imap4             117\n",
      "domain            116\n",
      "discard           116\n",
      "systat            115\n",
      "iso_tsap          115\n",
      "echo              112\n",
      "shell             112\n",
      "rje               111\n",
      "sql_net           110\n",
      "whois             110\n",
      "printer           109\n",
      "                ...  \n",
      "vmnet             106\n",
      "uucp              106\n",
      "uucp_path         106\n",
      "klogin            106\n",
      "ssh               105\n",
      "nnsp              105\n",
      "supdup            105\n",
      "hostnames         104\n",
      "login             104\n",
      "efs               103\n",
      "daytime           103\n",
      "netbios_ns        102\n",
      "link              102\n",
      "pop_2             101\n",
      "ldap              101\n",
      "http_443           99\n",
      "netbios_dgm        99\n",
      "exec               99\n",
      "name               98\n",
      "kshell             98\n",
      "ctf                97\n",
      "netstat            95\n",
      "Z39_50             92\n",
      "IRC                43\n",
      "urh_i              14\n",
      "X11                11\n",
      "tim_i               7\n",
      "pm_dump             1\n",
      "red_i               1\n",
      "tftp_u              1\n",
      "Name: 2, Length: 66, dtype: int64\n",
      "Var[2] (after) distribution:\n",
      " 14    281400\n",
      "45    110893\n",
      "22     64293\n",
      "50      9723\n",
      "40      7237\n",
      "11      5863\n",
      "19      4721\n",
      "13      1642\n",
      "18       798\n",
      "17       670\n",
      "61       538\n",
      "56       513\n",
      "39       380\n",
      "3        328\n",
      "43       202\n",
      "59       157\n",
      "6        126\n",
      "47       120\n",
      "20       117\n",
      "24       117\n",
      "10       116\n",
      "9        116\n",
      "55       115\n",
      "25       115\n",
      "49       112\n",
      "12       112\n",
      "48       111\n",
      "65       110\n",
      "51       110\n",
      "44       109\n",
      "       ...  \n",
      "63       106\n",
      "62       106\n",
      "4        106\n",
      "26       106\n",
      "52       105\n",
      "54       105\n",
      "37       105\n",
      "21       104\n",
      "30       104\n",
      "8        103\n",
      "15       103\n",
      "34       102\n",
      "29       102\n",
      "42       101\n",
      "28       101\n",
      "23        99\n",
      "16        99\n",
      "33        99\n",
      "32        98\n",
      "27        98\n",
      "7         97\n",
      "36        95\n",
      "2         92\n",
      "0         43\n",
      "60        14\n",
      "1         11\n",
      "58         7\n",
      "41         1\n",
      "46         1\n",
      "57         1\n",
      "Name: 2, Length: 66, dtype: int64\n",
      "Var[3] (before) distribution:\n",
      " SF        378440\n",
      "S0         87007\n",
      "REJ        26875\n",
      "RSTR         903\n",
      "RSTO         579\n",
      "SH           107\n",
      "S1            57\n",
      "S2            24\n",
      "RSTOS0        11\n",
      "S3            10\n",
      "OTH            8\n",
      "Name: 3, dtype: int64\n",
      "Var[3] (after) distribution:\n",
      " 9     378440\n",
      "5      87007\n",
      "1      26875\n",
      "4        903\n",
      "2        579\n",
      "10       107\n",
      "6         57\n",
      "7         24\n",
      "3         11\n",
      "8         10\n",
      "0          8\n",
      "Name: 3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "handle_categorical(testdata)\n",
    "handle_categorical(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494021, 42) (311029, 42)\n"
     ]
    }
   ],
   "source": [
    "print(traindata.shape, testdata.shape)\n",
    "X = traindata.iloc[:,0:41]\n",
    "Y = traindata.iloc[:,41]\n",
    "C = testdata.iloc[:,41]\n",
    "T = testdata.iloc[:,0:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "\n",
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Model Hidden Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = nn.MLPClassifier(activation='logistic' ,hidden_layer_sizes=(15,20), max_iter=10,solver='sgd', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.49829577\n",
      "Iteration 2, loss = 0.49500504\n",
      "Iteration 3, loss = 0.49394134\n",
      "Iteration 4, loss = 0.49223700\n",
      "Iteration 5, loss = 0.48915807\n",
      "Iteration 6, loss = 0.48283069\n",
      "Iteration 7, loss = 0.46770396\n",
      "Iteration 8, loss = 0.42500888\n",
      "Iteration 9, loss = 0.31346921\n",
      "Iteration 10, loss = 0.17769351\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(15, 20), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=10, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "Elapsed time 0:00:16.287574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminos/esprit/4nids/decision/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=16, microseconds=287574)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=init_chrono()\n",
    "model1.fit(traindata, trainlabel)\n",
    "print(model1)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model1.predict(testdata)\n",
    "np.savetxt('./predictedDT1.txt', predicted, fmt='%01d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50411  10182]\n",
      " [ 13959 236477]]\n",
      "True Positive Rate: 0.944\n",
      "False Positve Rate: 0.168\n",
      "True Negative Rate: 0.832\n",
      "False Negative Rate: 0.056\n",
      "Accuracy\n",
      "0.922\n",
      "precision\n",
      "0.871\n",
      "recall\n",
      "0.888\n",
      "f-score\n",
      "0.879\n",
      "***************************************************************\n",
      "Elapsed time 0:00:25.174956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=25, microseconds=174956)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "avg= 'macro'\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted, average=avg)\n",
    "precision = precision_score(expected, predicted , average=avg)\n",
    "f1 = f1_score(expected, predicted , average=avg)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tnr=float((cm[0][0])/np.sum(cm[0]))\n",
    "fpr=float((cm[0][1])/np.sum(cm[0]))\n",
    "tpr = float((cm[1][1])/np.sum(cm[1]))\n",
    "fnr = float((cm[1][0])/np.sum(cm[1]))\n",
    "print(\"True Positive Rate: %.3f\" %tpr)\n",
    "print(\"False Positve Rate: %.3f\" %fpr)\n",
    "print(\"True Negative Rate: %.3f\" %tnr)\n",
    "print(\"False Negative Rate: %.3f\" %fnr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "print(\"***************************************************************\")\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Model hidden layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.MLPClassifier(activation='logistic' ,hidden_layer_sizes=(20,), max_iter=10,solver='sgd', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.47923913\n",
      "Iteration 2, loss = 0.39825907\n",
      "Iteration 3, loss = 0.26632786\n",
      "Iteration 4, loss = 0.16678754\n",
      "Iteration 5, loss = 0.11786571\n",
      "Iteration 6, loss = 0.09250247\n",
      "Iteration 7, loss = 0.07789792\n",
      "Iteration 8, loss = 0.06882631\n",
      "Iteration 9, loss = 0.06285006\n",
      "Iteration 10, loss = 0.05872717\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=10, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "Elapsed time 0:00:12.312365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminos/esprit/4nids/decision/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=12, microseconds=312365)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=init_chrono()\n",
    "model2.fit(traindata, trainlabel)\n",
    "print(model2)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model2.predict(testdata)\n",
    "np.savetxt('./predictedDT2.txt', predicted, fmt='%01d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 57441   3152]\n",
      " [ 23547 226889]]\n",
      "True Positive Rate: 0.906\n",
      "False Positve Rate: 0.052\n",
      "True Negative Rate: 0.948\n",
      "False Negative Rate: 0.094\n",
      "Accuracy\n",
      "0.914\n",
      "precision\n",
      "0.848\n",
      "recall\n",
      "0.927\n",
      "f-score\n",
      "0.878\n",
      "***************************************************************\n",
      "Elapsed time 0:02:34.906664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=154, microseconds=906664)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "avg= 'macro'\n",
    "accuracy_mod2 = accuracy_score(expected, predicted)\n",
    "recall_mod2 = recall_score(expected, predicted, average=avg)\n",
    "precision_mod2 = precision_score(expected, predicted , average=avg)\n",
    "f1_mod2 = f1_score(expected, predicted , average=avg)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tnr_mod2=float((cm[0][0])/np.sum(cm[0]))\n",
    "fpr_mod2=float((cm[0][1])/np.sum(cm[0]))\n",
    "tpr_mod2 = float((cm[1][1])/np.sum(cm[1]))\n",
    "fnr_mod2 = float((cm[1][0])/np.sum(cm[1]))\n",
    "print(\"True Positive Rate: %.3f\" %tpr_mod2)\n",
    "print(\"False Positve Rate: %.3f\" %fpr_mod2)\n",
    "print(\"True Negative Rate: %.3f\" %tnr_mod2)\n",
    "print(\"False Negative Rate: %.3f\" %fnr_mod2)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy_mod2)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision_mod2)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall_mod2)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1_mod2)\n",
    "\n",
    "print(\"***************************************************************\")\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Model learning_rate_init=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = nn.MLPClassifier(activation='logistic' ,hidden_layer_sizes=(5,), max_iter=10,solver='sgd', verbose=True, learning_rate='constant', learning_rate_init=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04008824\n",
      "Iteration 2, loss = 0.02756512\n",
      "Iteration 3, loss = 0.02532387\n",
      "Iteration 4, loss = 0.02297718\n",
      "Iteration 5, loss = 0.02049638\n",
      "Iteration 6, loss = 0.01891104\n",
      "Iteration 7, loss = 0.01814683\n",
      "Iteration 8, loss = 0.01757086\n",
      "Iteration 9, loss = 0.01725618\n",
      "Iteration 10, loss = 0.01689181\n",
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
      "       learning_rate_init=0.5, max_iter=10, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=True, warm_start=False)\n",
      "Elapsed time 0:00:09.752780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminos/esprit/4nids/decision/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=9, microseconds=752780)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=init_chrono()\n",
    "model3.fit(traindata, trainlabel)\n",
    "print(model3)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model3.predict(testdata)\n",
    "np.savetxt('./predictedDT3.txt', predicted, fmt='%01d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58767   1826]\n",
      " [ 22839 227597]]\n",
      "True Positive Rate: 0.909\n",
      "False Positve Rate: 0.030\n",
      "True Negative Rate: 0.970\n",
      "False Negative Rate: 0.091\n",
      "Accuracy\n",
      "0.921\n",
      "precision\n",
      "0.856\n",
      "recall\n",
      "0.939\n",
      "f-score\n",
      "0.888\n",
      "***************************************************************\n",
      "Elapsed time 0:00:16.617169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=16, microseconds=617169)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "avg= 'macro'\n",
    "accuracy_mod3 = accuracy_score(expected, predicted)\n",
    "recall_mod3 = recall_score(expected, predicted, average=avg)\n",
    "precision_mod3 = precision_score(expected, predicted , average=avg)\n",
    "f1_mod3 = f1_score(expected, predicted , average=avg)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tnr_mod3=float((cm[0][0])/np.sum(cm[0]))\n",
    "fpr_mod3=float((cm[0][1])/np.sum(cm[0]))\n",
    "tpr_mod3 = float((cm[1][1])/np.sum(cm[1]))\n",
    "fnr_mod3 = float((cm[1][0])/np.sum(cm[1]))\n",
    "print(\"True Positive Rate: %.3f\" %tpr_mod3)\n",
    "print(\"False Positve Rate: %.3f\" %fpr_mod3)\n",
    "print(\"True Negative Rate: %.3f\" %tnr_mod3)\n",
    "print(\"False Negative Rate: %.3f\" %fnr_mod3)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy_mod3)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision_mod3)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall_mod3)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1_mod3)\n",
    "\n",
    "print(\"***************************************************************\")\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compare accuracy performance of the obtained trained model and IDS assessment criteria: \n",
    "    (I) detected attacks, \n",
    "    (ii) false positive rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better is model1\n"
     ]
    }
   ],
   "source": [
    "def Compare(*args):\n",
    "    max_model=args[0]\n",
    "    for i in args[1:]:\n",
    "        if i[1]>max_model[1]:\n",
    "            max_model=i\n",
    "        elif i[1]==max_model[1]:\n",
    "            if i[2]<max_model[2]:\n",
    "                max_model=i\n",
    "    print(\"The best Model is \"+max_model)\n",
    "    \n",
    "def compare(predicat, *args):\n",
    "    max_m = args[0]\n",
    "    for i in args[1:]:\n",
    "        if predicat(i, max_m) != False:\n",
    "            max_m = i\n",
    "    print(\"Better is {}\".format(max_m[0]))\n",
    "\n",
    "def best_tpr_if_equal_least_fpr(x, y):\n",
    "    if x[1] > y[1]:\n",
    "        return True\n",
    "    elif x[1] == y[1]:\n",
    "        if x[2] > y[2]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "m1 = (\"model1\", tpr, fpr)\n",
    "m2 = (\"model2\", tpr_mod2, fpr_mod2)\n",
    "m3 = (\"model3\", tpr_mod3, fpr_mod3)\n",
    "\n",
    "compare(best_tpr_if_equal_least_fpr, m1, m2, m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III:  Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Build a decision tree for a binary classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compare false positives to best model obtained with neural net resuults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494021, 42) (311029, 42)\n"
     ]
    }
   ],
   "source": [
    "print(traindata.shape, testdata.shape)\n",
    "X_train = traindata.iloc[:,0:41]\n",
    "y_train = traindata.iloc[:,41]\n",
    "y_test = testdata.iloc[:,41]\n",
    "X_test = testdata.iloc[:,0:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = np.array(y_test)\n",
    "trainlabel = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Elapsed time 0:00:01.379895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=1, microseconds=379895)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training, choose model by commenting/uncommenting clf=\n",
    "t= init_chrono()\n",
    "DTclf = DecisionTreeClassifier(criterion='entropy', splitter='best',\n",
    "                             max_depth=None, min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0,\n",
    "                             max_features=None,\n",
    "                             random_state=None,\n",
    "                             max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.0,\n",
    "                             class_weight=None,\n",
    "                             presort=False)\n",
    "print(\"Training model\")\n",
    "\n",
    "DTtrained_model= DTclf.fit(X_train, trainlabel)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using the test set \n",
      "(311029,)\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "print (\"Predicting using the test set \")\n",
    "y_pred = DTclf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9999979757945513\n",
      "Test_Score:  0.9281578245115407\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "print (\"Training Score:\", DTtrained_model.score(X_train, trainlabel))\n",
    "\n",
    "print (\"Test_Score: \", DTtrained_model.score(X_test, testlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By_class: [0.8418445  0.95352276]\n",
      "Global: 0.8976836315449059\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import f1_score\n",
    "print('By_class:',f1_score(testlabel, y_pred, average=None ))\n",
    "print('Global:', f1_score(testlabel, y_pred, average='macro' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing performance metrics\n",
      "Confusion matrix:\n",
      " [[ 59470   1123]\n",
      " [ 21222 229214]]\n",
      "Error:  0.07184217548845928\n"
     ]
    }
   ],
   "source": [
    "print (\"Computing performance metrics\")\n",
    "results = confusion_matrix(testlabel, y_pred)\n",
    "error = zero_one_loss(testlabel, y_pred)\n",
    "\n",
    "print (\"Confusion matrix:\\n\", results)\n",
    "print (\"Error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing variables to coordonate comparaison with other models\n",
    "expected = testlabel\n",
    "predicted = y_pred\n",
    "np.savetxt('./predictedDT_Dec_Tree.txt', predicted, fmt='%01d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59470   1123]\n",
      " [ 21222 229214]]\n",
      "True Positive Rate: 0.915\n",
      "False Positve Rate: 0.019\n",
      "True Negative Rate: 0.981\n",
      "False Negative Rate: 0.085\n",
      "Accuracy\n",
      "0.928\n",
      "precision\n",
      "0.866\n",
      "recall\n",
      "0.948\n",
      "f-score\n",
      "0.898\n",
      "***************************************************************\n",
      "Elapsed time 0:00:24.850196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=24, microseconds=850196)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "avg= 'macro'\n",
    "accuracy_DTmod = accuracy_score(expected, predicted)\n",
    "recall_DTmod = recall_score(expected, predicted, average=avg)\n",
    "precision_DTmod = precision_score(expected, predicted , average=avg)\n",
    "f1_DTmod = f1_score(expected, predicted , average=avg)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tnr_DTmod=float((cm[0][0])/np.sum(cm[0]))\n",
    "fpr_DTmod=float((cm[0][1])/np.sum(cm[0]))\n",
    "tpr_DTmod = float((cm[1][1])/np.sum(cm[1]))\n",
    "fnr_DTmod = float((cm[1][0])/np.sum(cm[1]))\n",
    "print(\"True Positive Rate: %.3f\" %tpr_DTmod)\n",
    "print(\"False Positve Rate: %.3f\" %fpr_DTmod)\n",
    "print(\"True Negative Rate: %.3f\" %tnr_DTmod)\n",
    "print(\"False Negative Rate: %.3f\" %fnr_DTmod)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy_DTmod)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision_DTmod)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall_DTmod)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1_DTmod)\n",
    "\n",
    "print(\"***************************************************************\")\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better is ANN model1\n",
      "False Positive are more significant with ANN model1\n"
     ]
    }
   ],
   "source": [
    "#Comparing Decision Tree model with the best ANN model (model1)\n",
    "m1 = (\"ANN model1\", tpr, fpr)\n",
    "m2 = (\"Decision Tree model\", tpr_DTmod, fpr_DTmod)\n",
    "compare(best_tpr_if_equal_least_fpr, m1, m2)\n",
    "#Comparing FalsePositves\n",
    "\n",
    "if fpr>fpr_DTmod:\n",
    "    print(\"False Positive are more significant with ANN model1\")\n",
    "else:\n",
    "    print(\"False Positive are more significant with Decision Tree model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Support Vector Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)-Build an Ids based on  2 svm by selecting the more accurate one: \n",
    "    (1)  SVM with a linear kernel \n",
    "    (2)  SVM with an rbf kernel an rbf svm kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)-  Compare the accuracy of svm models, ANN and decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)- Comapre computaional cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)- Can you find a tradeoff between accuracy and training cost and select the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMclf_linear=svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    }
   ],
   "source": [
    "t= init_chrono()\n",
    "print(\"Training model\")\n",
    "SVMclf_linear.fit(X_train,trainlabel)\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <hr>\n",
    "Copyright &copy; Nov-2018 Dr.Amir Esseghir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
