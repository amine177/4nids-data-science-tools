{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://esprit.tn\"><img src = \"https://upload.wikimedia.org/wikipedia/commons/f/ff/Logo_ESPRIT_Ariana.jpg\" width = 300, align = \"center\"></a>\n",
    "\n",
    "\n",
    "\n",
    "<h1 align=center><font size = 5>Lab 9: Supervised learning -  Artificial Neural Networks (ANN) </font></h1>\n",
    "\n",
    "Estimated duration: 90 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 9: IDS BASED ON MACHINE LEARNING TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim through this lab to build a robust intrusion detection system (IDS) based on a set of machine learning techinques.\n",
    "Various techniques will be explored and experimented to assess IDS robustness according to two criteria:\n",
    "    - maximizing the number of atatcks  detected \n",
    "    - reducing the number of false positive alerts\n",
    "The experiemtal study will cover the following methods:\n",
    "    - ANN\n",
    "    - Decision trees / random forest\n",
    "    - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Data loading and preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data preprare columns for ANN as done in the mini_lab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pnd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, classification_report,auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000040\n",
      "Elapsed time 0:00:00.000029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=29)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "t=datetime.datetime.now()\n",
    "print(datetime.datetime.now()- t)\n",
    "\n",
    "def init_chrono():\n",
    "    return datetime.datetime.now()\n",
    "\n",
    "def elapsed_time(t):\n",
    "    if t:\n",
    "        delta = init_chrono() - t\n",
    "        print ('Elapsed time', delta)\n",
    "        return delta \n",
    "    \n",
    "# test\n",
    "t = init_chrono()\n",
    "elapsed_time(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "print(sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data (494021, 42) \n",
      " test_data: (311029, 42)\n"
     ]
    }
   ],
   "source": [
    "data_path = './'\n",
    "traindata = pnd.read_csv(data_path+'train.csv', header=None)\n",
    "testdata = pnd.read_csv(data_path+'test.csv', header=None)\n",
    "\n",
    "print('train_data', traindata.shape, '\\n', 'test_data:', testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dist(df_column, tag = 'Column'):\n",
    "    if not df_column.empty: \n",
    "        dist = df_column.value_counts()\n",
    "        print(\"%s distribution:\\n\" %tag, dist)\n",
    "#Test\n",
    "#show_dist(traindata[41], tag=\"train dataset before \")  \n",
    "\n",
    "\n",
    "def get_categorical(dataframe):\n",
    "    types = dataframe.dtypes\n",
    "    i = 0\n",
    "    lst_cat=[]\n",
    "    for var in types:\n",
    "        if var == 'object':\n",
    "            print(i)\n",
    "            lst_cat.append(i)\n",
    "        i=i+1\n",
    "    return lst_cat\n",
    "\n",
    "def handle_categorical(dataframe):\n",
    "    if type(dataframe) != pnd.DataFrame:\n",
    "        return None \n",
    "\n",
    "    lst= get_categorical(dataframe)\n",
    "    \n",
    "    print('%d variables are categorical %s ' %(len(lst), lst))\n",
    "    for var_cat in lst:\n",
    "        try:\n",
    "            enc = sk.preprocessing.label.LabelEncoder()\n",
    "            tmp = dataframe\n",
    "            dataframe[var_cat] = enc.fit_transform(dataframe[var_cat])\n",
    "            try:\n",
    "                show_dist(tmp[var_cat], 'Var[' + str(var_cat) + '] (before)')\n",
    "                show_dist(dataframe[var_cat], 'Var[' + str(var_cat) + '] (after)')\n",
    "            except NameError as nmE:\n",
    "                print(nmE)\n",
    "        except Exception as e:\n",
    "            print('Exception: Unable to convert categorical variable ', var_cat, e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "3 variables are categorical [1, 2, 3] \n",
      "Var[1] (before) distribution:\n",
      " 0    283602\n",
      "1    190065\n",
      "2     20354\n",
      "Name: 1, dtype: int64\n",
      "Var[1] (after) distribution:\n",
      " 0    283602\n",
      "1    190065\n",
      "2     20354\n",
      "Name: 1, dtype: int64\n",
      "Var[2] (before) distribution:\n",
      " 14    281400\n",
      "45    110893\n",
      "22     64293\n",
      "50      9723\n",
      "40      7237\n",
      "11      5863\n",
      "19      4721\n",
      "13      1642\n",
      "18       798\n",
      "17       670\n",
      "61       538\n",
      "56       513\n",
      "39       380\n",
      "3        328\n",
      "43       202\n",
      "59       157\n",
      "6        126\n",
      "47       120\n",
      "20       117\n",
      "24       117\n",
      "10       116\n",
      "9        116\n",
      "55       115\n",
      "25       115\n",
      "49       112\n",
      "12       112\n",
      "48       111\n",
      "65       110\n",
      "51       110\n",
      "44       109\n",
      "       ...  \n",
      "63       106\n",
      "62       106\n",
      "4        106\n",
      "26       106\n",
      "52       105\n",
      "54       105\n",
      "37       105\n",
      "21       104\n",
      "30       104\n",
      "8        103\n",
      "15       103\n",
      "34       102\n",
      "29       102\n",
      "42       101\n",
      "28       101\n",
      "23        99\n",
      "16        99\n",
      "33        99\n",
      "32        98\n",
      "27        98\n",
      "7         97\n",
      "36        95\n",
      "2         92\n",
      "0         43\n",
      "60        14\n",
      "1         11\n",
      "58         7\n",
      "41         1\n",
      "46         1\n",
      "57         1\n",
      "Name: 2, Length: 66, dtype: int64\n",
      "Var[2] (after) distribution:\n",
      " 14    281400\n",
      "45    110893\n",
      "22     64293\n",
      "50      9723\n",
      "40      7237\n",
      "11      5863\n",
      "19      4721\n",
      "13      1642\n",
      "18       798\n",
      "17       670\n",
      "61       538\n",
      "56       513\n",
      "39       380\n",
      "3        328\n",
      "43       202\n",
      "59       157\n",
      "6        126\n",
      "47       120\n",
      "20       117\n",
      "24       117\n",
      "10       116\n",
      "9        116\n",
      "55       115\n",
      "25       115\n",
      "49       112\n",
      "12       112\n",
      "48       111\n",
      "65       110\n",
      "51       110\n",
      "44       109\n",
      "       ...  \n",
      "63       106\n",
      "62       106\n",
      "4        106\n",
      "26       106\n",
      "52       105\n",
      "54       105\n",
      "37       105\n",
      "21       104\n",
      "30       104\n",
      "8        103\n",
      "15       103\n",
      "34       102\n",
      "29       102\n",
      "42       101\n",
      "28       101\n",
      "23        99\n",
      "16        99\n",
      "33        99\n",
      "32        98\n",
      "27        98\n",
      "7         97\n",
      "36        95\n",
      "2         92\n",
      "0         43\n",
      "60        14\n",
      "1         11\n",
      "58         7\n",
      "41         1\n",
      "46         1\n",
      "57         1\n",
      "Name: 2, Length: 66, dtype: int64\n",
      "Var[3] (before) distribution:\n",
      " 9     378440\n",
      "5      87007\n",
      "1      26875\n",
      "4        903\n",
      "2        579\n",
      "10       107\n",
      "6         57\n",
      "7         24\n",
      "3         11\n",
      "8         10\n",
      "0          8\n",
      "Name: 3, dtype: int64\n",
      "Var[3] (after) distribution:\n",
      " 9     378440\n",
      "5      87007\n",
      "1      26875\n",
      "4        903\n",
      "2        579\n",
      "10       107\n",
      "6         57\n",
      "7         24\n",
      "3         11\n",
      "8         10\n",
      "0          8\n",
      "Name: 3, dtype: int64\n",
      "1\n",
      "2\n",
      "3\n",
      "3 variables are categorical [1, 2, 3] \n",
      "Var[1] (before) distribution:\n",
      " 0    164969\n",
      "1    119357\n",
      "2     26703\n",
      "Name: 1, dtype: int64\n",
      "Var[1] (after) distribution:\n",
      " 0    164969\n",
      "1    119357\n",
      "2     26703\n",
      "Name: 1, dtype: int64\n",
      "Var[2] (before) distribution:\n",
      " 14    164352\n",
      "46     78510\n",
      "22     41237\n",
      "50      8268\n",
      "44      3972\n",
      "11      3160\n",
      "19      2223\n",
      "41      2185\n",
      "56      2077\n",
      "18       837\n",
      "13       547\n",
      "25       333\n",
      "17       291\n",
      "53       195\n",
      "3        150\n",
      "59        82\n",
      "40        80\n",
      "12        69\n",
      "10        68\n",
      "4         66\n",
      "30        66\n",
      "20        65\n",
      "37        65\n",
      "47        65\n",
      "35        64\n",
      "60        63\n",
      "7         63\n",
      "26        62\n",
      "39        62\n",
      "61        62\n",
      "       ...  \n",
      "23        60\n",
      "9         60\n",
      "29        59\n",
      "34        59\n",
      "38        59\n",
      "5         58\n",
      "48        58\n",
      "45        58\n",
      "55        57\n",
      "52        56\n",
      "62        56\n",
      "32        56\n",
      "2         55\n",
      "15        55\n",
      "51        54\n",
      "8         53\n",
      "49        53\n",
      "63        53\n",
      "36        53\n",
      "64        52\n",
      "27        50\n",
      "6         50\n",
      "54        50\n",
      "21        48\n",
      "0         24\n",
      "42        16\n",
      "1         15\n",
      "58         7\n",
      "24         2\n",
      "57         1\n",
      "Name: 2, Length: 65, dtype: int64\n",
      "Var[2] (after) distribution:\n",
      " 14    164352\n",
      "46     78510\n",
      "22     41237\n",
      "50      8268\n",
      "44      3972\n",
      "11      3160\n",
      "19      2223\n",
      "41      2185\n",
      "56      2077\n",
      "18       837\n",
      "13       547\n",
      "25       333\n",
      "17       291\n",
      "53       195\n",
      "3        150\n",
      "59        82\n",
      "40        80\n",
      "12        69\n",
      "10        68\n",
      "4         66\n",
      "30        66\n",
      "20        65\n",
      "37        65\n",
      "47        65\n",
      "35        64\n",
      "60        63\n",
      "7         63\n",
      "26        62\n",
      "39        62\n",
      "61        62\n",
      "       ...  \n",
      "23        60\n",
      "9         60\n",
      "29        59\n",
      "34        59\n",
      "38        59\n",
      "5         58\n",
      "48        58\n",
      "45        58\n",
      "55        57\n",
      "52        56\n",
      "62        56\n",
      "32        56\n",
      "2         55\n",
      "15        55\n",
      "51        54\n",
      "8         53\n",
      "49        53\n",
      "63        53\n",
      "36        53\n",
      "64        52\n",
      "27        50\n",
      "6         50\n",
      "54        50\n",
      "21        48\n",
      "0         24\n",
      "42        16\n",
      "1         15\n",
      "58         7\n",
      "24         2\n",
      "57         1\n",
      "Name: 2, Length: 65, dtype: int64\n",
      "Var[3] (before) distribution:\n",
      " 9     248379\n",
      "1      41945\n",
      "5      18012\n",
      "2       1393\n",
      "4        872\n",
      "8        289\n",
      "10        84\n",
      "6         27\n",
      "7         22\n",
      "0          4\n",
      "3          2\n",
      "Name: 3, dtype: int64\n",
      "Var[3] (after) distribution:\n",
      " 9     248379\n",
      "1      41945\n",
      "5      18012\n",
      "2       1393\n",
      "4        872\n",
      "8        289\n",
      "10        84\n",
      "6         27\n",
      "7         22\n",
      "0          4\n",
      "3          2\n",
      "Name: 3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "traindata[41] = traindata[41].map(lambda x: 1 if x != 'normal.' else 0)\n",
    "testdata[41] = testdata[41].map(lambda x: 1 if x != 'normal.' else 0)\n",
    "\n",
    "# handling categorical data\n",
    "handle_categorical(traindata)\n",
    "handle_categorical(testdata)\n",
    "\n",
    "# creating values and classes\n",
    "x_train, y_train = traindata.iloc[:, :41], traindata.iloc[:, 41]\n",
    "x_test, y_test = testdata.iloc[:, :41], testdata.iloc[:, 41]\n",
    "# normalizing\n",
    "scaler = Normalizer().fit(x_train)\n",
    "trainX = scaler.transform(x_train)\n",
    "\n",
    "scaler = Normalizer().fit(x_test)\n",
    "testX = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(y_train)\n",
    "\n",
    "testdata = np.array(testX)\n",
    "testlabel = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Build 3 neural networks with respecitvely 2 hidden layers, one hidden layer, and a learning rate equal to .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neural_network as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first one\n",
    "# print(nn.MLPClassifier.__doc__)\n",
    "model1 = nn.MLPClassifier(activation='logistic',\n",
    "                          hidden_layer_sizes=(2,),\n",
    "                          max_iter=10,solver='sgd',\n",
    "                          verbose=True,\n",
    "                          learning_rate='constant',\n",
    "                          learning_rate_init=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04297154\n",
      "Iteration 2, loss = 0.03081398\n",
      "Iteration 3, loss = 0.02798865\n",
      "Iteration 4, loss = 0.02645478\n",
      "Iteration 5, loss = 0.02565081\n",
      "Iteration 6, loss = 0.02515808\n",
      "Iteration 7, loss = 0.02477040\n",
      "Iteration 8, loss = 0.02439204\n",
      "Iteration 9, loss = 0.02406671\n",
      "Iteration 10, loss = 0.02376612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminos/esprit/4nids/decision/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(2,), learning_rate='constant',\n",
       "       learning_rate_init=0.5, max_iter=10, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(traindata, trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second model\n",
    "model2 = nn.MLPClassifier(activation='logistic',\n",
    "                         hidden_layer_sizes=(1,),\n",
    "                         max_iter=10,\n",
    "                         solver='sgd',\n",
    "                         verbose=True,\n",
    "                         learning_rate='constant',\n",
    "                         learning_rate_init=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04653822\n",
      "Iteration 2, loss = 0.03683141\n",
      "Iteration 3, loss = 0.03653846\n",
      "Iteration 4, loss = 0.03651475\n",
      "Iteration 5, loss = 0.03638192\n",
      "Iteration 6, loss = 0.03616684\n",
      "Iteration 7, loss = 0.03616427\n",
      "Iteration 8, loss = 0.03620227\n",
      "Iteration 9, loss = 0.03612422\n",
      "Iteration 10, loss = 0.03612710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminos/esprit/4nids/decision/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
       "       learning_rate_init=0.5, max_iter=10, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(traindata, trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = nn.MLPClassifier(activation='logistic',\n",
    "                         hidden_layer_sizes=(1,),\n",
    "                         max_iter=10,\n",
    "                         solver='sgd',\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53675236\n",
      "Iteration 2, loss = 0.49483910\n",
      "Iteration 3, loss = 0.49016344\n",
      "Iteration 4, loss = 0.47071230\n",
      "Iteration 5, loss = 0.41000609\n",
      "Iteration 6, loss = 0.30996182\n",
      "Iteration 7, loss = 0.22350157\n",
      "Iteration 8, loss = 0.16783493\n",
      "Iteration 9, loss = 0.13314749\n",
      "Iteration 10, loss = 0.11076962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminos/esprit/4nids/decision/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=10, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(traindata, trainlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compare accuracy performance of the obtained trained model and IDS assessment criteria: \n",
    "    (I) detected attacks, \n",
    "    (ii) false positive rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = model1.predict(testdata)\n",
    "predicted2 = model2.predict(testdata)\n",
    "predicted3 = model3.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_KPIs(expected, predicted, avg='macro'):\n",
    "    t = init_chrono()\n",
    "    accuracy = accuracy_score(expected, predicted)\n",
    "    recall = recall_score(expected, predicted, average=avg)\n",
    "    precision = precision_score(expected, predicted , average=avg)\n",
    "    f1 = f1_score(expected, predicted , average=avg)\n",
    "    cm = metrics.confusion_matrix(expected, predicted)\n",
    "    print('Confusion matrix:\\n',cm)\n",
    "    tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "    fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "    print(\"Accuracy 0_class: %.3f\" %tpr)\n",
    "    print(\"Accuracy 1_class: %.3f\" %fpr)\n",
    "    print(\"Accuracy: %.3f\" %accuracy)\n",
    "    print(\"Precision: %.3f\" %precision)\n",
    "    print(\"Recall: %.3f\" %recall)\n",
    "    print(\"F1_score: %.3f\" %f1)\n",
    "\n",
    "    print(\"***************************************************************\")\n",
    "    elapsed_time(t)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 58976   1617]\n",
      " [ 56374 194062]]\n",
      "Accuracy 0_class: 0.973\n",
      "Accuracy 1_class: 0.775\n",
      "Accuracy: 0.814\n",
      "Precision: 0.752\n",
      "Recall: 0.874\n",
      "F1_score: 0.770\n",
      "***************************************************************\n",
      "Elapsed time 0:00:00.434618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 58976,   1617],\n",
       "       [ 56374, 194062]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_KPIs(testlabel, predicted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 59088   1505]\n",
      " [ 57119 193317]]\n",
      "Accuracy 0_class: 0.975\n",
      "Accuracy 1_class: 0.772\n",
      "Accuracy: 0.812\n",
      "Precision: 0.750\n",
      "Recall: 0.874\n",
      "F1_score: 0.768\n",
      "***************************************************************\n",
      "Elapsed time 0:00:00.415717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 59088,   1505],\n",
       "       [ 57119, 193317]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_KPIs(testlabel, predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 56934   3659]\n",
      " [ 18318 232118]]\n",
      "Accuracy 0_class: 0.940\n",
      "Accuracy 1_class: 0.927\n",
      "Accuracy: 0.929\n",
      "Precision: 0.871\n",
      "Recall: 0.933\n",
      "F1_score: 0.897\n",
      "***************************************************************\n",
      "Elapsed time 0:00:00.410534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 56934,   3659],\n",
       "       [ 18318, 232118]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_KPIs(testlabel, predicted3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III:  Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Build a decision tree for a binary classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compare false positives to best model obtained with neural net resuults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Support Vector Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)-Build an Ids based on  2 svm by selecting the more accurate one: \n",
    "    (1)  SVM with a linear kernel \n",
    "    (2)  SVM with an rbf kernel an rbf svm kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)-  Compare the accuracy of svm models, ANN and decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)- Comapre computaional cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)- Can you find a tradeoff between accuracy and training cost and select the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <hr>\n",
    "Copyright &copy; Nov-2018 Dr.Amir Esseghir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
